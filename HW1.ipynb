{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'normlize1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-228-8a00f1b40575>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlemma\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mf'{prev}={normlize1(form)}'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             \u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlemma\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'{'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34mf'{lemma}={normlize1(form)}'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mprev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlemma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'normlize1' is not defined"
     ]
    }
   ],
   "source": [
    "def normalize(form):\n",
    "    if form in {'м', 'ж', 'с', 'мо', 'мн', 'жо', 'жн', 'со', 'сн', 'мо-жо'}:\n",
    "        return 'S'\n",
    "    elif form == 'п':\n",
    "        return 'A'\n",
    "    elif form in {'св', 'нсв'}:\n",
    "        return 'V'\n",
    "    elif form == 'предл.':\n",
    "        return 'PR'\n",
    "    elif form == 'союз':\n",
    "        return 'CONJ'\n",
    "    else:\n",
    "        return 'ADV'\n",
    "    \n",
    "def normalize1(form):\n",
    "    if form == 'NOUN':\n",
    "        return 'S'\n",
    "    elif form == 'ADJF':\n",
    "        return 'A'\n",
    "    elif form in ['VERB', ]\n",
    "\n",
    "    \n",
    "inf = open('odict.csv', 'r', encoding='windows-1251')\n",
    "words = {}\n",
    "for line in inf.readlines():\n",
    "    kek = line.split(',')\n",
    "    lemma = kek[0].lower()\n",
    "    form = normalize(kek[1])\n",
    "    lemmaform = '{' + f'{lemma}={form}' + '}'\n",
    "    words[lemma] = lemmaform\n",
    "    for wd in kek[2:]:\n",
    "        words[wd.lower()] = lemmaform\n",
    "\n",
    "inf_dict = open('dict.opcorpora.txt', 'r')\n",
    "prev = ''\n",
    "for i in range(200):\n",
    "    num = inf_dict.readline()\n",
    "    if num == '':\n",
    "        break\n",
    "    num = int(num)\n",
    "    s = inf_dict.readline()\n",
    "    kek = s.split('\\t')\n",
    "    lemma = kek[0].lower()\n",
    "    form = kek[1].split(',')[0]\n",
    "    if lemma not in words:\n",
    "        if form == 'VERB':\n",
    "            words[lemma] = '{' + f'{prev}={normlize1(form)}' + '}'\n",
    "        else:\n",
    "            words[lemma] = '{' + f'{lemma}={normlize1(form)}' + '}'\n",
    "            \n",
    "    s = inf_dict.readline()\n",
    "    while s != '\\n':\n",
    "        word = s.split('\\t')[0].lower()\n",
    "        s = inf_dict.readline()\n",
    "        if word in words:\n",
    "            continue\n",
    "        if form == 'VERB':\n",
    "            words[lemma] = '{' + f'{prev}={normlize1(form)}' + '}'\n",
    "        else:\n",
    "            words[lemma] = '{' + f'{lemma}={normlize1(form)}' + '}'\n",
    "            \n",
    "    prev = lemma\n",
    "\n",
    "conj_file = open('conj.txt', 'r')\n",
    "for line in conj_file.readlines():\n",
    "    conj = line[:-1]\n",
    "    words[conj] = '{' + f'{conj}=CONJ' + '}'\n",
    "    \n",
    "prep_file = open('prep.txt', 'r')\n",
    "for line in prep_file.readlines():\n",
    "    prep = line[:-1]\n",
    "    words[prep] = '{' + f'{prep}=PR' + '}'\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(word):\n",
    "    return word + words[word.lower()] if word.lower() in words else word + '{' + f'{word}=ADV' + '}'\n",
    "        \n",
    "        \n",
    "def lemmatize_all(text):\n",
    "    tokens = re.findall('[\\\\w|-]+', text)\n",
    "    return ' '.join(list(map(lemmatize, tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'баре{бар=S} маре{мара=S} динамо-машина{динамо-машина=S}'"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize_all('баре маре динамо-машина')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_file = open('dataset_1.txt', 'r')\n",
    "res_file = open('result.txt', 'w')\n",
    "for line in sample_file.readlines():\n",
    "    res_file.write(lemmatize_all(line) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
